{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84209,"databundleVersionId":9414711,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"# General-purpose libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# TensorFlow and Keras for deep learning\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import EfficientNetV2L\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n\n# Sklearn utilities for evaluation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-23T10:49:32.193052Z","iopub.execute_input":"2024-11-23T10:49:32.193440Z","iopub.status.idle":"2024-11-23T10:49:43.882703Z","shell.execute_reply.started":"2024-11-23T10:49:32.193399Z","shell.execute_reply":"2024-11-23T10:49:43.882022Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load & Read Data","metadata":{}},{"cell_type":"code","source":"# Paths\nimage_dir = '/kaggle/input/computer-vision-xm/images/kaggle/working/Reorganized_Data/images/'\nlabels_csv = '/kaggle/input/computer-vision-xm/train.csv'\n\n# Load the CSV file with labels\nlabels_df = pd.read_csv(labels_csv)\nlabels_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-23T10:49:43.884069Z","iopub.execute_input":"2024-11-23T10:49:43.884600Z","iopub.status.idle":"2024-11-23T10:49:43.916549Z","shell.execute_reply.started":"2024-11-23T10:49:43.884571Z","shell.execute_reply":"2024-11-23T10:49:43.915649Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# Image size and batch size\nIMG_SIZE = 224\nBATCH_SIZE = 32\n\n# Preprocess Images\ndef load_and_preprocess_image(image_path):\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))  # Resize for EfficientNetV2M\n    image = preprocess_input(image)  # EfficientNetV2M preprocessing\n    return image\n\nimages = []\nlabels = []\n\nfor _, row in labels_df.iterrows():\n    image_path = os.path.join(image_dir, row['Images'])\n    images.append(load_and_preprocess_image(image_path))\n    labels.append(row['Labels'])\n\n# Convert to numpy arrays\nX = np.array(images)\ny = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2024-11-23T10:49:43.917606Z","iopub.execute_input":"2024-11-23T10:49:43.917891Z","iopub.status.idle":"2024-11-23T10:59:00.560634Z","shell.execute_reply.started":"2024-11-23T10:49:43.917865Z","shell.execute_reply":"2024-11-23T10:59:00.559617Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Split The Data","metadata":{}},{"cell_type":"code","source":"# Split Data into Training and Validation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"Training data: {X_train.shape}, Validation data: {X_val.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-23T10:59:00.563086Z","iopub.execute_input":"2024-11-23T10:59:00.563925Z","iopub.status.idle":"2024-11-23T10:59:01.147713Z","shell.execute_reply.started":"2024-11-23T10:59:00.563882Z","shell.execute_reply":"2024-11-23T10:59:01.146778Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Data Augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\nval_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\nval_generator = val_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-11-23T10:59:01.148699Z","iopub.execute_input":"2024-11-23T10:59:01.148984Z","iopub.status.idle":"2024-11-23T10:59:01.153641Z","shell.execute_reply.started":"2024-11-23T10:59:01.148958Z","shell.execute_reply":"2024-11-23T10:59:01.152697Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Building Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import ConvNeXtXLarge\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\n\n# Load and Build the ConvNeXtXLarge Model\nbase_model = ConvNeXtXLarge(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False  # Freeze the base model initially\n\n# Build the Model\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),  # Pooling to reduce dimensionality\n    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),  # Add L2 regularization\n    Dropout(0.5),  # Regularization to prevent overfitting\n    Dense(1, activation='sigmoid')  # Binary classification output\n])\n\n# Compile the Model\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n\n# View Model Summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-23T10:59:01.154559Z","iopub.execute_input":"2024-11-23T10:59:01.154855Z","iopub.status.idle":"2024-11-23T10:59:03.771606Z","shell.execute_reply.started":"2024-11-23T10:59:01.154831Z","shell.execute_reply":"2024-11-23T10:59:03.770781Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Initial Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\n# Set up learning rate scheduler\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_loss',  # Monitor validation loss\n    factor=0.5,  # Reduce the learning rate by half\n    patience=3,  # Number of epochs with no improvement before reducing learning rate\n    verbose=1\n)\n\n# Define EarlyStopping callback\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    restore_best_weights=True\n)\n\n# Train the Model\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=15,\n    callbacks=[early_stopping,lr_scheduler],\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-23T10:59:03.772614Z","iopub.execute_input":"2024-11-23T10:59:03.772889Z","iopub.status.idle":"2024-11-23T11:04:01.714060Z","shell.execute_reply.started":"2024-11-23T10:59:03.772862Z","shell.execute_reply":"2024-11-23T11:04:01.713278Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fine-Tune Model","metadata":{}},{"cell_type":"code","source":"# Fine-Tuning the model\nbase_model.trainable = True  # Unfreeze base model layers\n\n# Recompile the model with a smaller learning rate for fine-tuning\nmodel.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model again (fine-tuning)\nfine_tuning_history = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=10,\n    callbacks=[early_stopping, lr_scheduler],\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:04:01.715161Z","iopub.execute_input":"2024-11-23T11:04:01.715438Z","iopub.status.idle":"2024-11-23T11:10:46.900977Z","shell.execute_reply.started":"2024-11-23T11:04:01.715411Z","shell.execute_reply":"2024-11-23T11:10:46.899936Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save The Model","metadata":{}},{"cell_type":"code","source":"# Save the model\nmodel.save('leaf_disease_classifier.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:10:46.902521Z","iopub.execute_input":"2024-11-23T11:10:46.902938Z","iopub.status.idle":"2024-11-23T11:10:47.677155Z","shell.execute_reply.started":"2024-11-23T11:10:46.902907Z","shell.execute_reply":"2024-11-23T11:10:47.676334Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluating The Model","metadata":{}},{"cell_type":"code","source":"# Predictions on validation data\ny_pred = model.predict(X_val, batch_size=BATCH_SIZE)\ny_pred_classes = np.where(y_pred > 0.5, 1, 0)\n\n# Evaluate performance\nprint(f\"Accuracy: {accuracy_score(y_val, y_pred_classes)}\")\nprint(\"Classification Report:\")\nprint(classification_report(y_val, y_pred_classes))\n\n# Confusion Matrix\ncm = confusion_matrix(y_val, y_pred_classes)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-23T11:10:47.680251Z","iopub.execute_input":"2024-11-23T11:10:47.680869Z","iopub.status.idle":"2024-11-23T11:10:56.478480Z","shell.execute_reply.started":"2024-11-23T11:10:47.680831Z","shell.execute_reply":"2024-11-23T11:10:56.477600Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loss-epoch Graph","metadata":{}},{"cell_type":"code","source":"# Plot training & validation accuracy and loss over epochs\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:10:56.479608Z","iopub.execute_input":"2024-11-23T11:10:56.479998Z","iopub.status.idle":"2024-11-23T11:10:56.705441Z","shell.execute_reply.started":"2024-11-23T11:10:56.479957Z","shell.execute_reply":"2024-11-23T11:10:56.704666Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Make Predictions For Submission","metadata":{}},{"cell_type":"code","source":"# Paths for Test Data\ntest_csv = '/kaggle/input/computer-vision-xm/test.csv'\ntest_df = pd.read_csv(test_csv)\n\nimage_filenames = test_df['Images'].tolist()\nimage_paths = [os.path.join(image_dir, img) for img in image_filenames if img.lower().endswith('.jpg')]\n\n# Preprocess Test Images\ndef preprocess_test_image(image_path):\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (224, 224))\n    image = preprocess_input(image)  # Consistent with training preprocessing\n    return image\n\ntest_images = np.array([preprocess_test_image(path) for path in image_paths])\n\n# Predictions\npredictions = model.predict(test_images, batch_size=BATCH_SIZE)\npredicted_labels = (predictions > 0.5).astype(int).flatten()\n\n# Create Submission File\nsubmission_df = pd.DataFrame({\n    'Images': [os.path.basename(path) for path in image_paths],\n    'Labels': predicted_labels\n})\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n\nprint('Submission file saved.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:10:56.706675Z","iopub.execute_input":"2024-11-23T11:10:56.707276Z","iopub.status.idle":"2024-11-23T11:13:23.506237Z","shell.execute_reply.started":"2024-11-23T11:10:56.707236Z","shell.execute_reply":"2024-11-23T11:13:23.505244Z"}},"outputs":[],"execution_count":null}]}